# Multimodal Dataset

## A Multi-Source Dataset Including Hyspectral, Infrared and RGB Images. ## 

ðŸ’¡ [![](https://img.shields.io/badge/Data-@GoogleDrive-brightgreen.svg)]( https://drive.google.com/drive/folders/1-1dcT8M72wbBWfftMbmG88sBRyZQgYOe?usp=sharing) ðŸ’¡

The proposed dataset utilized three modalities: RGB, push-broom visible hyperspectral camera, and snapshot infrared hyperspectral camera, each offering distinct spatial and spectral resolutions. Different camera systems exhibit varying photometric properties, resulting in a trade-off between spatial and spectral resolution. RGB cameras typically offer high spatial resolution but limited spectral resolution, while hyperspectral cameras possess high spectral resolution at the expense of spatial resolution. Moreover, hyperspectral cameras themselves employ different capturing techniques and spectral ranges, further complicating the acquisition of comprehensive data. By integrating the photometric properties of these modalities, a single synthetic hyperspectral image can be generated, facilitating the exploration of broader spectralspatial relationships for improved analysis, monitoring, and decision-making across various fields.

<div  align="center">    
 <img src="https://github.com/spectral-3D-lab/multimodal-dataset/blob/main/multimodal_data/minions_apples.png" width = "666"  align=center />
</div>

